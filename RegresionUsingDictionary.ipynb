{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU3Jf21mWqGCnpr2MBUbaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mxag11z/EMO/blob/main/RegresionUsingDictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z2: Mejoraremos la estrategia 2 usando lexicones o diccionarios de palabras que contengan un score de emocion por palabra, usaremos dos distintos y entrenaremos nuestros modelos de regresion en cada uno para ver cual da mejores resultados. Sin embargo para la estrategia 2 debemos tener el conjunto de entrenamiento en español para poder probarlo correctamente en el corpus de test que esta en español. Para el Diccionario NRC no hay problema, pues está en español ya directamente, por otro lado para el de Buecher solo hay en ingles, por lo que tocará traducirlo al español."
      ],
      "metadata": {
        "id": "9L1eX1sBg5ob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cs5d2_uBSnfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ef872c9-e57f-4d25-ffb1-d2a17a40c6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "import sklearn.metrics\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFtQo7_is8-Q",
        "outputId": "a2322a3a-e6a4-45b4-a937-784830cb85e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dfSlTE1Ig2__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data2(emotion):\n",
        "    \"\"\"\n",
        "    Lee los datos de train y test para una emoción\n",
        "    \"\"\"\n",
        "    # Datos de entrenamiento\n",
        "    with open(f\"/content/drive/MyDrive/PLN project/data/en_train&dev_translatedEs/train/translated_trainToEs_{emotion}.txt\", 'r', encoding='utf-8') as f:\n",
        "        train_X = f.readlines()\n",
        "    with open(f\"/content/drive/MyDrive/PLN project/data/en/train/{emotion}_labels.txt\", 'r', encoding='utf-8') as f:\n",
        "        train_y = [float(line.strip()) for line in f.readlines()]\n",
        "\n",
        "    # Datos de test\n",
        "    with open(f\"/content/drive/MyDrive/PLN project/data/es/test/{emotion}.txt\", 'r', encoding='utf-8') as f:\n",
        "        test_X = f.readlines()\n",
        "    with open(f\"/content/drive/MyDrive/PLN project/data/es/test/{emotion}_labels.txt\", 'r', encoding='utf-8') as f:\n",
        "        test_y = [float(line.strip()) for line in f.readlines()]\n",
        "\n",
        "    return (train_X, train_y), (test_X, test_y)"
      ],
      "metadata": {
        "id": "3-O9DyAHtHIu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nrc_lexicon(file_path):\n",
        "    \"\"\"\n",
        "    Carga el NRC lexicon español solo para joy, anger, sadness y fear\n",
        "    \"\"\"\n",
        "    lexicon = {}\n",
        "    valid_emotions = {'joy', 'anger', 'sadness', 'fear'}\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) >= 4:\n",
        "                _, emotion, score, spanish_word = parts[:4]\n",
        "\n",
        "                # Solo procesar las emociones que nos interesan\n",
        "                if emotion.lower() in valid_emotions:\n",
        "                    if emotion not in lexicon:\n",
        "                        lexicon[emotion] = {}\n",
        "                    lexicon[emotion][spanish_word] = float(score)\n",
        "    return lexicon"
      ],
      "metadata": {
        "id": "U4_APuYTuRPc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_buechel_lexicon(file_path):\n",
        "    \"\"\"\n",
        "    Carga el Buechel lexicon (formato TSV) solo para Joy, Anger, Sadness y Fear\n",
        "    \"\"\"\n",
        "    lexicon = {}\n",
        "    valid_emotions = {'Joy', 'Anger', 'Sadness', 'Fear'}\n",
        "\n",
        "    # Leer el archivo TSV con pandas\n",
        "    df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "    # Procesar cada emoción válida\n",
        "    for emotion in valid_emotions:\n",
        "        emotion_lower = emotion.lower()  # Convertir a minúsculas\n",
        "        lexicon[emotion_lower] = {}\n",
        "\n",
        "        # Para cada palabra, guardar su puntuación\n",
        "        for _, row in df.iterrows():\n",
        "            word = row['Word']\n",
        "            try:\n",
        "                score = float(row[emotion])\n",
        "                lexicon[emotion_lower][word] = score\n",
        "            except (ValueError, KeyError):\n",
        "                continue\n",
        "\n",
        "    return lexicon"
      ],
      "metadata": {
        "id": "2iqzEzAnuZhs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lexicon_features(text, lexicon, emotion):\n",
        "    \"\"\"\n",
        "    Extrae características de un lexicon para un texto\n",
        "    \"\"\"\n",
        "    words = text.lower().split()\n",
        "    scores = [lexicon[emotion].get(word, 0) for word in words]\n",
        "\n",
        "    return {\n",
        "        'max_score': max(scores) if scores else 0,\n",
        "        'mean_score': np.mean(scores) if scores else 0,\n",
        "        'sum_score': sum(scores),\n",
        "        'count_words': sum(1 for score in scores if score > 0)\n",
        "    }"
      ],
      "metadata": {
        "id": "ODbNBEJOwP0e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_emotion_regressor_comparison(emotion, alpha=100):\n",
        "    \"\"\"\n",
        "    Compara diferentes combinaciones de lexicones\n",
        "    \"\"\"\n",
        "    # Cargar lexicones\n",
        "    nrc_lexicon = load_nrc_lexicon(\"/content/drive/MyDrive/PLN project/data/lexicons/NRC-spanish.txt\")\n",
        "    buechel_lexicon = load_buechel_lexicon(\"/content/drive/MyDrive/PLN project/data/lexicons/Buechel_spa_lex.tsv\")\n",
        "    ##print(nrc_lexicon);\n",
        "    ##print(buechel_lexicon);\n",
        "    # Cargar datos\n",
        "    (train_X, train_y), (test_X, test_y) = read_data2(emotion)\n",
        "\n",
        "    # BOW features (base)\n",
        "    vectorizer = CountVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1,2),\n",
        "        lowercase=True,\n",
        "        strip_accents=None,\n",
        "        binary=True\n",
        "    )\n",
        "    X_train_bow = vectorizer.fit_transform(train_X)\n",
        "    X_test_bow = vectorizer.transform(test_X)\n",
        "\n",
        "    # NRC lexicon features\n",
        "    X_train_nrc = np.array([list(get_lexicon_features(text, nrc_lexicon, emotion).values())\n",
        "                           for text in train_X])\n",
        "    X_test_nrc = np.array([list(get_lexicon_features(text, nrc_lexicon, emotion).values())\n",
        "                          for text in test_X])\n",
        "\n",
        "    # Buechel lexicon features\n",
        "    X_train_buechel = np.array([list(get_lexicon_features(text, buechel_lexicon, emotion).values())\n",
        "                               for text in train_X])\n",
        "    X_test_buechel = np.array([list(get_lexicon_features(text, buechel_lexicon, emotion).values())\n",
        "                              for text in test_X])\n",
        "\n",
        "    # Crear diferentes combinaciones de características\n",
        "    combinations = {\n",
        "        'BOW_only': (X_train_bow.toarray(), X_test_bow.toarray()),\n",
        "        'BOW_NRC': (np.hstack((X_train_bow.toarray(), X_train_nrc)),\n",
        "                   np.hstack((X_test_bow.toarray(), X_test_nrc))),\n",
        "        'BOW_Buechel': (np.hstack((X_train_bow.toarray(), X_train_buechel)),\n",
        "                       np.hstack((X_test_bow.toarray(), X_test_buechel))),\n",
        "        'BOW_NRC_Buechel': (np.hstack((X_train_bow.toarray(), X_train_nrc, X_train_buechel)),\n",
        "                           np.hstack((X_test_bow.toarray(), X_test_nrc, X_test_buechel)))\n",
        "    }\n",
        "\n",
        "    # Probar cada combinación\n",
        "    results = {}\n",
        "    for name, (X_train, X_test) in combinations.items():\n",
        "        # Entrenar modelo\n",
        "        model = linear_model.Ridge(alpha=alpha)\n",
        "        model.fit(X_train, train_y)\n",
        "\n",
        "        # Evaluar\n",
        "        preds = model.predict(X_test)\n",
        "        mae = sklearn.metrics.mean_absolute_error(test_y, preds)\n",
        "        results[name] = mae\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "xI-W4MssyMUd"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_all_emotions():\n",
        "    \"\"\"\n",
        "    Compara todas las combinaciones para cada emoción\n",
        "    \"\"\"\n",
        "    emotions = ['joy', 'anger', 'sadness', 'fear']\n",
        "    all_results = {}\n",
        "\n",
        "    for emotion in emotions:\n",
        "        print(f\"\\n-----Processing {emotion}\")\n",
        "        results = train_emotion_regressor_comparison(emotion)\n",
        "        all_results[emotion] = results\n",
        "\n",
        "        # Mostrar resultados para esta emoción\n",
        "        print(f\"\\nResultados para {emotion}:\")\n",
        "        for method, mae in results.items():\n",
        "            print(f\"{method}: MAE = {mae:.4f}\")\n",
        "\n",
        "    return all_results"
      ],
      "metadata": {
        "id": "fqGV_lMizgDg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_mejorados = compare_all_emotions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRuMrDcBz9Qv",
        "outputId": "97a8e3d9-2451-4e9a-c9f7-d3b57c26267e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-----Processing joy\n",
            "\n",
            "Resultados para joy:\n",
            "BOW_only: MAE = 0.2212\n",
            "BOW_NRC: MAE = 0.2203\n",
            "BOW_Buechel: MAE = 0.2185\n",
            "BOW_NRC_Buechel: MAE = 0.2178\n",
            "\n",
            "-----Processing anger\n",
            "\n",
            "Resultados para anger:\n",
            "BOW_only: MAE = 0.2254\n",
            "BOW_NRC: MAE = 0.2231\n",
            "BOW_Buechel: MAE = 0.2249\n",
            "BOW_NRC_Buechel: MAE = 0.2232\n",
            "\n",
            "-----Processing sadness\n",
            "\n",
            "Resultados para sadness:\n",
            "BOW_only: MAE = 0.2249\n",
            "BOW_NRC: MAE = 0.2215\n",
            "BOW_Buechel: MAE = 0.2254\n",
            "BOW_NRC_Buechel: MAE = 0.2224\n",
            "\n",
            "-----Processing fear\n",
            "\n",
            "Resultados para fear:\n",
            "BOW_only: MAE = 0.2147\n",
            "BOW_NRC: MAE = 0.2130\n",
            "BOW_Buechel: MAE = 0.2149\n",
            "BOW_NRC_Buechel: MAE = 0.2137\n"
          ]
        }
      ]
    }
  ]
}